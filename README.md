
takes two lists of words, in any language, and finds the rules and exceptions that classify them in a compact and non-redundant way.


given two lists of words, it calculates the frequencies of all their edge-grams (prefix & suffix), and finds the signals that best classify the lists, as well as their exceptions.

this logic is used to build the classifiers of nlp_compromise in all languages.


it is :boom:badasss:boom:

MIT
